FIS = function(layers, status_year){
  # layers used: fis_meancatch, fis_b_bmsy, fis_proparea_saup2rgn

  # catch data
  c = SelectLayersData(layers, layers='fis_meancatch', narrow = TRUE) %>%
    select(
      fao_saup_id    = id_chr,
      taxon_name_key = category,
      year,
      catch          = val_num)

  # separate out the region ids:
  c$fao_id    <- as.numeric(sapply(strsplit(as.character(c$fao_saup_id), "_"), function(x)x[1]))
  c$saup_id   <- as.numeric(sapply(strsplit(as.character(c$fao_saup_id), "_"), function(x)x[2]))
  c$TaxonName <- sapply(strsplit(as.character(c$taxon_name_key), "_"), function(x)x[1])
  c$TaxonKey  <- as.numeric(sapply(strsplit(as.character(c$taxon_name_key), "_"), function(x)x[2]))
  c$catch     <- as.numeric(c$catch)
  c$year      <- as.numeric(as.character(c$year))
  #Create Identifier for linking assessed stocks with country-level catches
  c$stock_id <- paste(as.character(c$TaxonName),
                      as.character(c$fao_id), sep="_")

  # b_bmsy data
  b = SelectLayersData(layers, layer='fis_b_bmsy', narrow = TRUE) %>%
    select(
      fao_id         = id_num,
      TaxonName      = category,
      year,
      bmsy           = val_num)
  # Identifier taxa/fao region:
  b$stock_id <- paste(b$TaxonName, b$fao_id, sep="_")
  b$bmsy     <- as.numeric(b$bmsy)
  b$fao_id   <- as.numeric(as.character(b$fao_id))
  b$year     <- as.numeric(as.character(b$year))


  # area data for saup to rgn conversion
  a = layers$data[['fis_proparea_saup2rgn']] %>%
    select(saup_id, rgn_id, prop_area)
  a$prop_area <- as.numeric(a$prop_area)
  a$saup_id   <- as.numeric(as.character(a$saup_id))
  a$rgn_id    <- as.numeric(as.character(a$rgn_id))

  # ------------------------------------------------------------------------
  # STEP 1. Merge the species status data with catch data
  #     AssessedCAtches: only taxa with catch status data
  # -----------------------------------------------------------------------
  AssessedCatches <- join(b, c,
                          by = c("stock_id", "year"), type="inner")

  # b,c by stock_id

  # include only taxa with species-level data
  AssessedCatches <- AssessedCatches[as.numeric(AssessedCatches$TaxonKey)>=600000, ]
  AssessedCatches$penalty <- 1

  # ------------------------------------------------------------------------
  # STEP 2. Estimate status data for catch taxa without species status
  #     UnAssessedCatches: taxa with catch status data
  # -----------------------------------------------------------------------
  UnAssessedCatches <- c[!(c$year %in% AssessedCatches$year &
                             c$stock_id %in% AssessedCatches$stock_id), ]

  # 2a.  Join UnAssessedCatches data to the b_bmsy summaries for each FAO/Year

  # Average status data for assessed stocks by FAO region for each year.
  # This is used as the starting estimate for unassesed stocks
  # Here, the Median b_bmsy was chosen for TaxonKey >= 600000
  # and Min b_bmsy for TaxonKey < 600000
  #  *************NOTE *****************************
  #  Using the minimum B/BMSY score as an starting point
  #  for the estimate of B/BMSY for unassessed taxa not
  #  identified to species level is very conservative.
  #  This is a parameter that can be changed.
  #  ***********************************************
  b_summary <- ddply(b, .(fao_id, year), summarize,
                     Medianb_bmsy=quantile(as.numeric(bmsy), probs=c(0.5)),
                     Minb_bmsy=min(as.numeric(bmsy)))

  UnAssessedCatches <- join(UnAssessedCatches, b_summary, by = c("fao_id", "year"),
                            type="left", match="all")

  # 2b.  Create a penalty variable based on taxa level:
  UnAssessedCatches$TaxonPenaltyCode <- substring(UnAssessedCatches$TaxonKey,1,1)

  # 2c. Create a penalty table for taxa not identified to species level
  #  *************NOTE *****************************
  #  In some cases, it may make sense to alter the
  #  penalty for not identifying fisheries catch data to
  #  species level.
  #  ***********************************************
  penaltyTable <- data.frame(TaxonPenaltyCode=1:6,
                             penalty=c(0.01, 0.25, 0.5, 0.8, 0.9, 1))
  # 2d.Merge with data
  UnAssessedCatches <- join(UnAssessedCatches, penaltyTable, by="TaxonPenaltyCode")

  # ------------------------------------------------------------------------
  # STEP 3. Calculate score for all taxa based on status (b/bmsy) and taxa
  # -----------------------------------------------------------------------

  #  *************NOTE *****************************
  #  These values can be altered
  #  ***********************************************
  alpha <- 0.5
  beta <- 0.25
  lowerBuffer <- 0.95
  upperBuffer <- 1.05

  ## Function to calculate score for different scenarios:
  score <- function(data, variable){
    #data <- AssessedCatches
    #variable <- "bmsy"
    ifelse(data[ ,variable]*data[, "penalty"]<lowerBuffer,
           data[ ,variable]*data[, "penalty"],
           ifelse(data[ ,variable]*data[, "penalty"]>upperBuffer,
                  ifelse(1-alpha*(data[ ,variable]*data[, "penalty"]
                                  -upperBuffer)>beta,
                         1-alpha*(data[ ,variable]*data[, "penalty"]-upperBuffer),beta),
                  1))
  }

  AssessedCatches$score <- score(data=AssessedCatches, variable="bmsy")

  # Median is used to calculate score for species with Taxon 6 coding
  UnAssessedCatchesT6 <- subset(UnAssessedCatches, penalty==1)
  UnAssessedCatchesT6$score <- score(UnAssessedCatchesT6, "Medianb_bmsy")

  UnAssessedCatches <- subset(UnAssessedCatches, penalty!=1)
  UnAssessedCatches$score <- score(UnAssessedCatches, "Medianb_bmsy")

  AllScores <- rbind(AssessedCatches[,c("TaxonName", "TaxonKey", "year", "fao_id", "saup_id", "catch","score")],
                     UnAssessedCatchesT6[,c("TaxonName", "TaxonKey", "year", "fao_id", "saup_id", "catch","score")],
                     UnAssessedCatches[,c("TaxonName", "TaxonKey", "year", "fao_id", "saup_id", "catch","score")])

  # ------------------------------------------------------------------------
  # STEP 4. Calculate status for each saup_id region
  # -----------------------------------------------------------------------

  # 4a. To calculate the weight (i.e, the relative catch of each stock per saup_id),
  # the mean catch of taxon i is divided by the
  # sum of mean catch of all species in region r, which is calculated as:

  smc <- ddply(.data = AllScores, .(year, saup_id), summarize,
               SumCatch = sum(catch))
  AllScores<-join(AllScores,smc,by = c("year","saup_id"))
  AllScores$wprop<-AllScores$catch/AllScores$SumCatch


  #  4b. The "score" and "weight" values per taxon per SAUP region are used to
  #    calculate a geometric weighted mean across taxa for each saup_id region
  geomMean <- ddply(.data = AllScores, .(saup_id, year), summarize, status_saup = prod(score^wprop))

  # ------------------------------------------------------------------------
  # STEP 5. Convert status from saup spatial scale to OHI spatial scale
  # -----------------------------------------------------------------------
  # In many cases the ohi reporting regions are comprised of multiple saup regions.
  # To correct for this, the proportion of each saup area of the total area of the
  # OHI region was calculated. This was used to calculate Status from the Status_saup.
  # This type of adjustment is omitted if the data were collected at the same spatial
  # scale as the collecting region.

  # Join region names/ids to Geom data
  geomMean <- join(a, geomMean, type="inner", by="saup_id") # merge km2 of shelf area with status results

  # weighted mean scores
  StatusData <- ddply(.data = geomMean, .(rgn_id, year), summarize, Status = sum(status_saup*prop_area))

  # 2013 status is based on 2011 data (most recent data)
  status = StatusData %>%
    filter(year==status_year) %>%
    mutate(
      score     = round(Status*100),
      dimension = 'status') %>%
    select(region_id=rgn_id, dimension, score)

  # ------------------------------------------------------------------------
  # STEP 6. Calculate trend
  # -----------------------------------------------------------------------
  trend = ddply(StatusData, .(rgn_id), function(x){
    mdl = lm(Status ~ year, data=x)
    data.frame(
      score     = round(coef(mdl)[['year']] * 5, 2),
      dimension = 'trend')}) %>%
    dplyr::select(region_id=rgn_id, dimension, score)
  # %>% semi_join(status, by = 'rgn_id')

  # assemble dimensions
  scores = rbind(status, trend) %>% mutate(goal='FIS')
  return(scores)
}


MAR = function(layers, status_year){
  # layers used: mar_harvest_tonnes, mar_harvest_species, mar_sustainability_score, mar_coastalpopn_inland25km, mar_trend_years
  harvest_tonnes <- SelectLayersData(layers, layers='mar_harvest_tonnes', narrow = TRUE) %>%
    select(rgn_id=id_num, species_code=category, year, tonnes=val_num)

  harvest_species <- SelectLayersData(layers, layers='mar_harvest_species', narrow = TRUE) %>%
    select(species_code=category, species=val_chr)

  sustainability_score <- SelectLayersData(layers, layers='mar_sustainability_score', narrow = TRUE) %>%
    select(rgn_id=id_num, species_code=category, sust_coeff=val_num)

  popn_inland25mi <- SelectLayersData(layers, layers='mar_coastalpopn_inland25km', narrow = TRUE) %>%
    select(rgn_id=id_num, year, popsum=val_num)


rky <-  harvest_tonnes %>%
    left_join(harvest_species, by = 'species_code') %>%
    left_join(sustainability_score, by = c('rgn_id', 'species_code'))

# fill in gaps with no data
rky <- spread(rky, year, tonnes)
rky <- gather(rky, "year", "tonnes", 5:dim(rky)[2])


# 4-year rolling mean of data
m <- rky %>%
  mutate(year = as.numeric(as.character(year))) %>%
  group_by(rgn_id, species, species_code, sust_coeff) %>%
  arrange(rgn_id, species, species_code, year) %>%
  mutate(sm_tonnes = zoo::rollapply(tonnes, 4, mean, na.rm=TRUE, partial=TRUE)) %>%
  ungroup()

# smoothed mariculture harvest * sustainability coefficient
m <- m %>%
  mutate(sust_tonnes = sust_coeff * sm_tonnes)


# aggregate all weighted timeseries per region, and divide by coastal human population
  ry = m %>%
    group_by(rgn_id, year) %>%
    summarize(sust_tonnes_sum = sum(sust_tonnes, na.rm=TRUE)) %>%  #na.rm = TRUE assumes that NA values are 0
    left_join(popn_inland25mi, by = c('rgn_id','year')) %>%
    mutate(mar_pop = sust_tonnes_sum / popsum) %>%
    ungroup()


  # get reference quantile based on argument years
    ref_95pct_data <- ry %>%
    filter(year <= status_year)

    ref_95pct <- quantile(ref_95pct_data$mar_pop, 0.95, na.rm=TRUE)

# identify reference rgn_id
ry_ref = ref_95pct_data %>%
  arrange(mar_pop) %>%
  filter(mar_pop >= ref_95pct)
  cat(sprintf('95th percentile for MAR ref pt is: %s\n', ref_95pct)) # rgn_id 25 = Thailand
  cat(sprintf('95th percentile rgn_id for MAR ref pt is: %s\n', ry_ref$rgn_id[1])) # rgn_id 25 = Thailand
tmp <- data.frame(MAR=c('quantile', 'region'), value=c(ref_95pct, ry_ref$rgn_id[1]))


ry = ry %>%
  mutate(status = ifelse(mar_pop / ref_95pct > 1,
                         1,
                         mar_pop / ref_95pct))
status <- ry %>%
  filter(year == status_year) %>%
  select(rgn_id, status) %>%
  mutate(status = round(status*100, 2))


# get MAR trend
trend = ry %>%
  group_by(rgn_id) %>%
  do(mdl = lm(status ~ year, data=., subset=year %in% (status_year-4):(status_year))) %>%
  summarize(rgn_id, trend = coef(mdl)['year'] * 5) %>%
  ungroup()

trend <- trend %>%
  mutate(trend = ifelse(trend>1, 1, trend)) %>%
  mutate(trend = ifelse(trend<(-1), (-1), trend)) %>%
  mutate(trend = round(trend, 2))

  # return scores
  scores = status %>%
    select(region_id = rgn_id,
           score     = status) %>%
    mutate(dimension='status') %>%
    rbind(
      trend %>%
        select(region_id = rgn_id,
               score     = trend) %>%
        mutate(dimension = 'trend')) %>%
    mutate(goal='MAR')

  return(scores)
}

FP = function(layers, scores){
  # weights
  w = rename(SelectLayersData(layers, layers='fp_wildcaught_weight', narrow = TRUE),
             c('id_num'='region_id', 'val_num'='w_FIS')); head(w)

  # scores
  s = dcast(scores, region_id + dimension ~ goal, value.var='score', subset=.(goal %in% c('FIS','MAR') & !dimension %in% c('pressures','resilience'))); head(s)

  # combine
  d = merge(s, w)
  d$w_MAR = 1 - d$w_FIS
  d$score = apply(d[,c('FIS','MAR','w_FIS', 'w_MAR')], 1, function(x){ weighted.mean(x[1:2], x[3:4], na.rm = TRUE) })
  d$goal = 'FP'

  # return all scores
  return(rbind(scores, d[,c('region_id','goal','dimension','score')]))
}


AO = function(layers,
              year_max,
              Sustainability=1.0){
  # cast data
  layers_data = SelectLayersData(layers, targets='AO')

  year_min=max(min(layers_data$year, na.rm = TRUE), year_max - 10)

  r <- layers_data %>%
    filter(layer == 'ao_access') %>%
    select(region_id=id_num, access=val_num)
  r <- na.omit(r)

  ry <- layers_data %>%
    filter(layer == 'ao_need') %>%
    select(region_id = id_num, year, need=val_num) %>%
    left_join(r)



#   ry = plyr::rename(reshape2::dcast(layers_data, id_num + year ~ layer, value.var='val_num',
#                     subset = (layer %in% c('ao_need'))),
#               c('id_num'='region_id', 'ao_need'='need')); head(ry); summary(ry)
#
#   r = na.omit(rename(dcast(layers_data, id_num ~ layer, value.var='val_num',
#                            subset = .(layer %in% c('ao_access'))),
#                      c('id_num'='region_id', 'ao_access'='access'))); head(r); summary(r)
#
#    ry = merge(ry, r); head(r); summary(r); dim(r)

  # model

  ry <- ry %>%
    mutate(Du = (1 - need) * (1 - access)) %>%
    mutate(statusData = (1 - Du) * Sustainability)

#   ry = within(ry,{
#     Du2 = (1.0 - need) * (1.0 - access)
#     statusData2 = ((1.0 - Du) * Sustainability)
#   })
#
  # status
  r.status <- ry %>%
    filter(year==year_max) %>%
    select(region_id, statusData) %>%
    mutate(status=statusData*100)
summary(r.status); dim(r.status)

  # trend
tmp <- data.frame(pet = c((rep(c('cat', 'dog'), each=4)), 'hamster'), year=c(1990:1993, 1994:1991, 2012))
tmp %>%
  group_by(pet) %>%
  arrange(year) %>%
  top_n(2, year)

r.trend <- ry %>%
  filter(year >= year_min) %>%
  filter(!is.na(statusData)) %>%
  group_by(region_id) %>%
  arrange(year) %>%
  top_n(5, year) %>%
  ungroup()


r.trend <- r.trend %>%
  group_by(region_id) %>%
  do(mdl = lm(statusData ~ year, data=.)) %>%
  summarize( region_id = region_id,
             trend = coef(mdl)['year']*5) %>%
  ungroup()



#   r.trend = ddply(subset(ry, year >= year_min), .(region_id), function(x)
#     {
#       if (length(na.omit(x$statusData))>1) {
#         # use only last valid 5 years worth of status data since year_min
#         d = data.frame(statusData=x$statusData, year=x$year)[tail(which(!is.na(x$statusData)), 5),]
#         trend = coef(lm(statusData ~ year, d))[['year']]*5
#       } else {
#         trend = NA
#       }
#       return(data.frame(trend=trend))
#     })

  # return scores
  scores = r.status %>%
    select(region_id, score=status) %>%
    mutate(dimension='status') %>%
    rbind(
      r.trend %>%
        select(region_id, score=trend) %>%
        mutate(dimension='trend')) %>%
    mutate(goal='AO') # dlply(scores, .(dimension), summary)
  return(scores)
}

NP <- function(scores, layers, year_max, debug = FALSE){
  ### Apr 2014: updated by @oharac to use dplyr, tidyr.
  # TODO: add smoothing a la PLoS 2013 manuscript # ??? CCO: done? is this the NP data_prep smoothing?

  ### new code version - load combined harvest variables
  r_cyanide    = layers$data[['np_cyanide']]
  r_blast      = layers$data[['np_blast']]
  hab_extent   = layers$data[['hab_extent']]

  ### FIS status for fish oil exposure
  FIS_status   <-  scores %>%
    filter(goal == 'FIS' & dimension == 'status') %>%
    select(rgn_id = region_id, score)


  ###########################################################.
  ### Here I define five main sub-functions.  The main script that
  ### actually calls these functions is at the very end of the NP section.
  ###   np_rebuild_harvest
  ###   np_calc_exposure
  ###   np_calc_risk
  ###   np_calc_sustainability
  ###   np_calc_scores

  np_rebuild_harvest <- function(layers) {
    ### Reassembles NP harvest information from separate data layers:
    ### [rgn_name  rgn_id  product  year  tonnes  tonnes_rel  prod_weight]
    #########################################.

    ## load data from layers dataframe
      rgns         <- layers$data[['rgn_labels']]
      h_tonnes     <- layers$data[['np_harvest_tonnes']]
      h_tonnes_rel <- layers$data[['np_harvest_tonnes_relative']]
      h_w          <- layers$data[['np_harvest_product_weight']]

    # merge harvest in tonnes and usd
    np_harvest <- h_tonnes %>%
      full_join(
        h_tonnes_rel,
        by=c('rgn_id', 'product', 'year')) %>%
          left_join(
            h_w %>%
              select(rgn_id, product, prod_weight = weight),
            by=c('rgn_id', 'product')) %>%
          left_join(
            rgns %>%
              select(rgn_id, rgn_name=label),
            by='rgn_id') %>%
          select(
            rgn_name, rgn_id, product, year,
            tonnes, tonnes_rel, prod_weight) %>%
          group_by(rgn_id, product)

    return(np_harvest)
  }


  np_calc_exposure <- function(np_harvest, hab_extent, FIS_status) {
    ### calculates NP exposure based on habitats (for corals, seaweeds,
    ### ornamentals, shells, sponges) and FIS status scores (for fish oil).
    ### Returns the first input data frame with a new column for exposure:
    ### [rgn_id rgn_name product year tonnes tonnes_rel prod_weight exposure]
    #########################################.

    ### Determine Habitat Areas for Exposure
    ### extract habitats used
    hab_coral <- hab_extent %>%
      filter(habitat == 'coral') %>%
      select(rgn_id, km2)
    hab_rocky   <- hab_extent %>%
      filter(habitat == 'rocky_reef') %>%
      select(rgn_id, km2)

    ### area for products having single habitats for exposure
    area_single_hab <- bind_rows(
      # corals in coral reef
        np_harvest %>%
        filter(product == 'corals') %>%
        left_join(
          hab_coral %>%
            filter(km2 > 0) %>%
            select(rgn_id, km2), by = 'rgn_id'),
      ### seaweeds in rocky reef
      np_harvest %>%
        filter(product == 'seaweeds') %>%
        left_join(
          hab_rocky %>%
            filter(km2 > 0) %>%
            select(rgn_id, km2), by = 'rgn_id'))

    ### area for products in both coral and rocky reef habitats: shells, ornamentals, sponges
    area_dual_hab <- np_harvest %>%
      filter(product %in% c('shells', 'ornamentals','sponges')) %>%
      left_join(
        hab_coral %>%
          filter(km2 > 0) %>%
          select(rgn_id, coral_km2 = km2),
        by = 'rgn_id') %>%
      left_join(
        hab_rocky %>%
          filter(km2 > 0) %>%
          select(rgn_id, rocky_km2 = km2),
        by = 'rgn_id') %>%
      rowwise() %>%
      mutate(
        km2 = sum(c(rocky_km2, coral_km2), na.rm = TRUE)) %>%
      filter(km2 > 0)

    ### Determine Exposure
    ### exposure: combine areas, get tonnes / area, and rescale with log transform
    np_exp <-
      bind_rows(
        area_single_hab,
        area_dual_hab %>%
          select(-rocky_km2, -coral_km2)) %>%
      mutate(
        expos_raw = ifelse(tonnes > 0 & km2 > 0, (tonnes / km2), 0)) %>%
      group_by(product) %>%
      mutate(
        expos_prod_max = (1 - .35)*max(expos_raw, na.rm = TRUE)) %>%
          ### Reduced max exposure:
          ###   .35 is the threshold for harvest peak used in status
      ungroup() %>%
      mutate(
        exposure = (log(expos_raw + 1) / log(expos_prod_max + 1)),
        exposure = ifelse(exposure > 1, 1, exposure)) %>%
      select(-km2, -expos_raw, -expos_prod_max)
        ### clean up columns

    ### add exposure for countries with (habitat extent == NA)
    np_exp <- np_exp %>%
      group_by(product) %>%
      mutate(mean_exp = mean(exposure, na.rm = TRUE)) %>%
      mutate(exposure = ifelse(is.na(exposure), mean_exp, exposure)) %>%
      select(-mean_exp) %>%
      ungroup()

    ### add exposure for fish_oil
    np_exp <- np_exp %>% bind_rows(
        np_harvest %>%
          filter(product=='fish_oil') %>%
          left_join(
            FIS_status %>%
              mutate(exposure = score / 100) %>%
#              mutate(exposure = ifelse(is.na(exposure), 0, exposure)) %>%
        ### ??? adding this ^^^ from below - now will filter only NAs in fish_oil exposure, not seaweeds and coral exposure
              select(rgn_id, exposure),
            by = 'rgn_id'))

    # ??? CCO: This assigns exposure to zero for ANY product with NA (fish oil, seaweeds, corals)
#     np_exp <- np_exp %>%
 #      mutate(exposure = ifelse(is.na(exposure), 0, exposure))

    return(np_exp)
  }

  np_calc_risk <- function(np_exp, r_cyanide, r_blast) {
    ### calculates NP risk based on:
    ###   ornamentals:      risk = 1 if blast or cyanide fishing
    ###   corals:           risk = 1 for all cases
    ###   shells, sponges:  risk = 0 for all cases
    ###   others:           risk = NA?
    ### Returns a data frame of risk, by product, by region:
    ###
    #########################################.

    ### Determine Risk

    ### risk for ornamentals set to 1 if blast or cyanide fishing present, based on Nature 2012 code
    ###  despite Nature 2012 Suppl saying Risk for ornamental fish is set to the "relative intensity of cyanide fishing"
    risk_orn <- r_cyanide %>%
      filter(!is.na(score) & score > 0) %>%
      select(rgn_id, cyanide = score) %>%
      merge(
        r_blast %>%
          filter(!is.na(score) & score > 0) %>%
          select(rgn_id, blast = score),
        all = TRUE) %>%
      mutate(ornamentals = 1)

    ### risk as binary
    np_risk <-
      ### fixed risk: corals (1), sponges (0) and shells (0)
      data.frame(
        rgn_id  = unique(np_harvest$rgn_id),
        corals  = 1,
        sponges = 0,
        shells  = 0) %>%
      ### ornamentals
      left_join(
        risk_orn %>%
          select(rgn_id, ornamentals),
        by = 'rgn_id')  %>%
      mutate(
        ornamentals = ifelse(is.na(ornamentals), 0, ornamentals)) %>%
      gather(product, risk, -rgn_id)
    return(np_risk)
  }

  np_calc_sustainability <- function(np_exp, np_risk) {
    ### calculates NP sustainability coefficient for each natural product, based
    ### on (1 - mean(c(exposure, risk))).  Returns first input dataframe with
    ### new columns for sustainability coefficient, and sustainability-adjusted
    ### NP product_status:
    ### [rgn_id  rgn_name  product  year  prod_weight  sustainability  product_status]
    #########################################.

    ### join Exposure (with harvest) and Risk
    np_sust <- np_exp %>%
      left_join(
        np_risk,
        by = c('rgn_id', 'product')) %>%
      rowwise() %>%
      mutate(sustainability = 1 - mean(c(exposure, risk), na.rm = TRUE))

    ### calculate rgn-product-year status
    np_sust <- np_sust %>%
      mutate(product_status = tonnes_rel * sustainability) %>%
      filter(rgn_name != 'DISPUTED') %>%
      select(-tonnes, -tonnes_rel, -risk, -exposure)

    return(np_sust)
  }

  np_calc_scores <- function(np_sust, year_max) {
    ### Calculates NP status for all production years for each region, based
    ### upon weighted mean of all products produced.
    ### From this, reports the most recent year as the NP status.
    ### Calculates NP trend for each region, based upon slope of a linear
    ### model over the past six years inclusive (five one-year intervals).
    ### Returns data frame with status and trend by region:
    ### [goal   dimension   region_id   score]
    #########################################.

    ### Calculate status, trends
    ### aggregate across products to rgn-year status, weighting by usd_rel
    np_status_all <- np_sust %>%
      filter(!is.na(product_status) & !is.na(prod_weight)) %>%
        ### ??? CCO: guadeloupe & martinique have NA for ornamental prod_weight.  Is this a gap-filling error?
      select(rgn_name, rgn_id, year, product, product_status, prod_weight) %>%
      group_by(rgn_id, year) %>%
      summarize(status = weighted.mean(product_status, prod_weight)) %>%
      filter(!is.na(status)) %>% # 1/0 produces NaN
      ungroup()

    #   if (debug){
    #     ### write out data


    #   }

    ### get current status
    np_status_current <- np_status_all %>%
      filter(year == year_max & !is.na(status)) %>%
      mutate(
        dimension = 'status',
        score     = round(status,4) * 100) %>%
      select(rgn_id, dimension, score)
    stopifnot(
      min(np_status_current$score, na.rm = TRUE) >= 0,
      max(np_status_current$score, na.rm = TRUE) <= 100)

    ### trend based on 5 intervals (6 years of data)
    np_trend <- np_status_all %>%
      filter(year <= year_max & year > (year_max - 5) & !is.na(status)) %>%
      group_by(rgn_id) %>%
      do(mdl = lm(status ~ year, data=.)) %>%
      summarize(
        rgn_id    = rgn_id,
        dimension = 'trend',
        score     = max(-1, min(1, coef(mdl)[['year']] * 5)))
    stopifnot(min(np_trend$score) >= -1, max(np_trend$score) <= 1)

    ### return scores
    np_scores <- np_status_current %>%
      full_join(np_trend) %>%
      mutate(goal = 'NP') %>%
      select(goal, dimension, region_id=rgn_id, score) %>%
      arrange(goal, dimension, region_id)

    return(np_scores)
  }

  ##########################################.
  ### Natural Products main starts here:

  np_harvest <- np_rebuild_harvest(layers)
  np_exp     <- np_calc_exposure(np_harvest, hab_extent, FIS_status)
  np_risk    <- np_calc_risk(np_exp, r_cyanide, r_blast)
  np_sust    <- np_calc_sustainability(np_exp, np_risk)
  np_scores  <- np_calc_scores(np_sust, year_max)

  return(np_scores)
}


  CS <- function(layers){
    # join layer data
    d <-
      plyr::join_all(
        list(
          layers$data[['hab_extent']] %>%
            select(rgn_id, habitat, km2),

          layers$data[['hab_health']] %>%
            select(rgn_id, habitat, health),

          layers$data[['hab_trend']] %>%
            select(rgn_id, habitat, trend)),

        by = c('rgn_id','habitat'), type='full') %>%
      select(rgn_id, habitat, km2, health, trend) %>%
      mutate(habitat = as.character(habitat))

    # limit to CP habitats and add rank
    habitat.rank <- c('mangrove'         = 139,
                      'saltmarsh'        = 210,
                      'seagrass'         = 83)

    d <- d %>%
      filter(habitat %in% names(habitat.rank)) %>%
      mutate(
        rank = habitat.rank[habitat],
        extent = ifelse(km2==0, NA, km2))

    if (nrow(d) > 0){
      # status
      scores_CS <- d %>%
        filter(!is.na(rank) & !is.na(health) & !is.na(extent)) %>%
        group_by(rgn_id) %>%
        summarize(
          score = pmin(1, sum(rank * health * extent, na.rm=TRUE) / (sum(extent * rank, na.rm=TRUE)) ) * 100,
          dimension = 'status')

      # trend
      d_trend <- d %>%
        filter(!is.na(rank) & !is.na(trend) & !is.na(extent))
      if (nrow(d_trend) > 0 ){
        scores_CS <- rbind_list(
          scores_CS,
          d_trend %>%
            group_by(rgn_id) %>%
            summarize(
              score = sum(rank * trend * extent, na.rm=TRUE) / (sum(extent*rank, na.rm=TRUE)),
              dimension = 'trend'))
      } else {
        scores_CS <- rbind_list(
          scores_CS,
          d %>%
            group_by(rgn_id) %>%
            summarize(
              score = NA,
              dimension = 'trend'))
      }

      ### output data file for checking and data review
      scores_check <- spread(scores_CS, dimension, score) %>%
        select(rgn_id, status, trend_score=trend)

      d_check <- d %>%
        select(rgn_id, habitat, extent, health, trend, rank) %>%
        arrange(rgn_id, habitat) %>%
        left_join(scores_check, by="rgn_id")

      ### end: output...

      scores_CS <- scores_CS %>%
        mutate(
          goal = 'CS') %>%
        select(region_id=rgn_id, goal, dimension, score)
    } else {
      scores_CS <- data.frame(
        goal      = character(0),
        dimension = character(0),
        region_id = integer(0),
        score     = numeric())
    }

    # return scores
    return(scores_CS)
  }



CP <- function(layers){
  # sum mangrove_offshore + mangrove_inland1km = mangrove to match with extent and trend
  m <- layers$data[['hab_extent']] %>%
    filter(habitat %in% c('mangrove_inland1km','mangrove_offshore')) %>%
    select(rgn_id, habitat, km2)

  if (nrow(m) > 0){
    m <- m %>%
      group_by(rgn_id) %>%
      summarize(km2 = sum(km2, na.rm = TRUE)) %>%
      mutate(habitat='mangrove') %>%
      ungroup()
  }

  # join layer data
  d <-
    plyr::join_all(
      list(
        layers$data[['hab_health']] %>%
          select(rgn_id, habitat, health),

        layers$data[['hab_trend']] %>%
          select(rgn_id, habitat, trend),

        # for habitat extent
        rbind_list(

          # do not use all mangrove
          layers$data[['hab_extent']] %>%
            filter(!habitat %in% c('mangrove','mangrove_inland1km','mangrove_offshore')) %>%
            select(rgn_id, habitat, km2),

          # just use inland1km and offshore
          m)),

      by = c('rgn_id','habitat'), type='full') %>%
    select(rgn_id, habitat, km2, health, trend)

  # limit to CP habitats and add rank
  habitat.rank <- c('coral'            = 4,
                    'mangrove'         = 4,
                    'saltmarsh'        = 3,
                    'seagrass'         = 1,
                    'seaice_shoreline' = 4)

  d <- d %>%
    filter(habitat %in% names(habitat.rank)) %>%
    mutate(
      rank = habitat.rank[habitat],
      extent = ifelse(km2==0, NA, km2))

  if (nrow(d) > 0){
    # status
    scores_CP <- d %>%
      filter(!is.na(rank) & !is.na(health) & !is.na(extent)) %>%
      group_by(rgn_id) %>%
      summarize(
        score = pmin(1, sum(rank * health * extent, na.rm=TRUE) / (sum(extent * rank, na.rm=TRUE)) ) * 100,
        dimension = 'status')

    # trend
    d_trend <- d %>%
      filter(!is.na(rank) & !is.na(trend) & !is.na(extent))
    if (nrow(d_trend) > 0 ){
      scores_CP <- rbind_list(
        scores_CP,
        d_trend %>%
          group_by(rgn_id) %>%
          summarize(
            score = sum(rank * trend * extent, na.rm=TRUE) / (sum(extent*rank, na.rm=TRUE)),
            dimension = 'trend'))
    } else {
      scores_CS <- rbind_list(
        scores_CS,
        d %>%
          group_by(rgn_id) %>%
          summarize(
            score = NA,
            dimension = 'trend'))
    }

    ### output data file for checking and data review
    scores_check <- spread(scores_CP, dimension, score) %>%
      select(rgn_id, status, trend_score=trend)

    d_check <- d %>%
      select(rgn_id, habitat, extent, health, trend, rank) %>%
      arrange(rgn_id, habitat) %>%
      left_join(scores_check, by="rgn_id")

    ### end: output...

    scores_CP <- scores_CP %>%
      mutate(
        goal = 'CP') %>%
      select(region_id=rgn_id, goal, dimension, score)
  } else {
    scores_CP <- data.frame(
      goal      = character(0),
      dimension = character(0),
      region_id = integer(0),
      score     = numeric())
  }

  # return scores
  return(scores_CP)
}


TR = function(layers, year_max, debug = FALSE, pct_ref = 90) {
  ### Updated July 2015 - Casey O'Hara
  ### * adjusted model to use percent employment in tourism when available.
  ### * set up layers for travel warnings.

  #Inputs:
  # * U  = tr_unemployment.csv:     Percent unemployment (0-100%)
  # * S_score  = tr_sustainability.csv:   TTCI score, not normalized (1-7)
  # * Ed = tr_jobs_tourism.csv:     Number of jobs, direct employment in tourism
  # * Ep = tr_jobs_pct_tourism.csv: Percent of direct tourism jobs
  # * L  = tr_jobs_total.csv:       Total labor force
  # formula:
  #  E       = ifelse(is.na(Ep), Ed / (L - (L * U)), Ep)    # Ep is direct percentage of labor in tourism; if not available, calc the hard way
  #  S       = (S_score - 1) / (7 - 1)                      # S_score is raw score (from 1:7).  Subtract 1 and normalize.
  #  Xtr     = E * S

  # get regions
  rgn_names = layers$data[[conf$config$layer_region_labels]] %>%
    select(rgn_id, rgn_name = label)

  tr_data  <- layers$data[['tr_jobs_tourism']]     %>%
    select(-layer) %>%
    full_join(layers$data[['tr_jobs_pct_tourism']] %>%
                select(-layer),
              by = c('rgn_id','year'))             %>%
    full_join(layers$data[['tr_unemployment']]     %>%
                select(-layer),
              by = c('rgn_id','year'))             %>%
    full_join(layers$data[['tr_jobs_total']]       %>%
                select(-layer),
              by = c('rgn_id','year'))             %>%
    full_join(layers$data[['tr_sustainability']]   %>%
                select(-layer),
              by = c('rgn_id'))                    %>%
    full_join(rgn_names, by = 'rgn_id')            %>%
    filter(year <= year_max)

  tr_model <- tr_data %>%
    mutate(
      E   = ifelse(is.na(Ep), Ed / (L - (L * U)), Ep),
      S   = (S_score - 1) / (7 - 1), # scale score from 1 to 7.
      Xtr = E * S ) %>%
    filter(year <= year_max & year > year_max - 5)
  # five data years, four intervals

  # regions with Travel Warnings at http://travel.state.gov/content/passports/english/alertswarnings.html
  rgn_travel_warnings <- layers$data[['tr_travelwarnings']] %>%
    select(rgn_name, multiplier) %>%
    left_join(rgn_names, by = 'rgn_name') %>%
    filter(!is.na(rgn_id))

  tr_model <- tr_model %>%
    left_join(rgn_travel_warnings %>%
                select(-rgn_name),
              by = 'rgn_id') %>%
    mutate(Xtr = ifelse(!is.na(multiplier), multiplier * Xtr, Xtr)) %>%
    select(-multiplier)

  ### Calculate status based on quantile reference (see function call for pct_ref)
  tr_model <- tr_model %>%
    select(rgn_id, rgn_name, year, Xtr) %>%
    left_join(tr_model %>%
                group_by(year) %>%
                summarize(Xtr_q = quantile(Xtr, probs = pct_ref/100, na.rm = TRUE)),
              by = 'year') %>%
    mutate(
      Xtr_rq  = ifelse(Xtr / Xtr_q > 1, 1, Xtr / Xtr_q)) # rescale to qth percentile, cap at 1


  # calculate trend
  tr_trend <- tr_model %>%
    filter(!is.na(Xtr_rq)) %>%
    arrange(year, rgn_id) %>%
    group_by(rgn_id) %>%
    do(mod = lm(Xtr_rq ~ year, data = .)) %>%
    do(data.frame(
      rgn_id    = .$rgn_id,
      dimension = 'trend',
      score     =  max(min(coef(.$mod)[['year']] * 5, 1), -1)))

  # get status (as last year's value)
  tr_status <- tr_model %>%
    arrange(year, rgn_id) %>%
    group_by(rgn_id) %>%
    summarize(
      dimension = 'status',
      score     = last(Xtr_rq) * 100)

  # bind status and trend by rows
  tr_score <- bind_rows(tr_status, tr_trend) %>%
    mutate(goal = 'TR')

  if (conf$config$layer_region_labels=='rgn_global'){
    # assign NA for uninhabitated islands
    unpopulated = layers$data[['le_popn']] %>%
      group_by(rgn_id) %>%
      filter(count==0) %>%
      select(rgn_id)
    tr_score$score = ifelse(tr_score$rgn_id %in% unpopulated$rgn_id, NA, tr_score$score)

    #     # replace North Korea value with 0
    #     tr_score$score[tr_score$rgn_id == 21] = 0
  }

  # return final scores
  scores = tr_score %>%
    select(region_id=rgn_id, goal, dimension, score)

  return(scores)
}
LIV_ECO = function(layers, subgoal){

  ## read in all data:

  # gdp, wages, jobs and workforce_size data
  le_gdp   = SelectLayersData(layers, layers='le_gdp')  %>%
    select(rgn_id = id_num, year, gdp_usd = val_num)

  le_wages = SelectLayersData(layers, layers='le_wage_sector_year') %>%
    select(rgn_id = id_num, year, sector = category, wage_usd = val_num)

  le_jobs  = SelectLayersData(layers, layers='le_jobs_sector_year') %>%
    select(rgn_id = id_num, year, sector = category, jobs = val_num)

  le_workforce_size = SelectLayersData(layers, layers='le_workforcesize_adj') %>%
    select(rgn_id = id_num, year, jobs_all = val_num)

  le_unemployment = SelectLayersData(layers, layers='le_unemployment') %>%
    select(rgn_id = id_num, year, pct_unemployed = val_num)

  # debug
  #     le_gdp            = read.csv('eez2014/layers/le_gdp.csv')
  #     le_wages          = read.csv('eez2014/layers/le_wage_sector_year.csv')
  #     le_jobs           = read.csv('eez2014/layers/le_jobs_sector_year.csv')
  #     le_workforce_size = read.csv('eez2014/layers/le_workforcesize_adj.csv')
  #     le_unemployment   = read.csv('eez2014/layers/le_unemployment.csv')

  # multipliers from Table S10 (Halpern et al 2012 SOM)
  multipliers_jobs = data.frame('sector' = c('tour','cf', 'mmw', 'wte','mar'),
                                'multiplier' = c(1, 1.582, 1.915, 1.88, 2.7)) # no multiplers for tour (=1)
  # multipliers_rev  = data.frame('sector' = c('mar', 'tour'), 'multiplier' = c(1.59, 1)) # not used because GDP data is not by sector


  # calculate employment counts
  le_employed = le_workforce_size %>%
    left_join(le_unemployment, by = c('rgn_id', 'year')) %>%
    mutate(proportion_employed = (100 - pct_unemployed) / 100,
           employed            = jobs_all * proportion_employed)

  # reworded from SOM p.26-27
  #reference point for wages is the reference region (r) with the highest average wages across all sectors.
  #Reference points for jobs (j) and revenue (e) employ a moving baseline. The two metrics (j, e) are calculated
  #as relative values: the value in the current year (or most recent year), c, relative to the value in a recent
  #moving reference period, r, defined as 5 years prior to c. This reflects an implicit goal of maintaining coastal
  #livelihoods and economies (L&E) on short time scales, allowing for decadal or generational shifts in what people
  #want and expect for coastal L&E. The most recent year c must be 2000 or later in order for the data to be included.

  liv =
    # adjust jobs
    le_jobs %>%
    left_join(multipliers_jobs, by = 'sector') %>%
    mutate(jobs_mult = jobs * multiplier) %>%  # adjust jobs by multipliers
    left_join(le_employed, by= c('rgn_id', 'year')) %>%
    mutate(jobs_adj = jobs_mult * proportion_employed) %>% # adjust jobs by proportion employed
    left_join(le_wages, by=c('rgn_id','year','sector')) %>%
    arrange(year, sector, rgn_id)

  # LIV calculations ----

  # LIV status
  liv_status = liv %>%
    filter(!is.na(jobs_adj) & !is.na(wage_usd))
  # aia/subcountry2014 crashing b/c no concurrent wage data, so adding this check
  if (nrow(liv_status)==0){
    liv_status = liv %>%
      select(region_id=rgn_id) %>%
      group_by(region_id) %>%
      summarize(
        goal      = 'LIV',
        dimension = 'status',
        score     = NA)
    liv_trend = liv %>%
      select(region_id=rgn_id) %>%
      group_by(region_id) %>%
      summarize(
        goal      = 'LIV',
        dimension = 'trend',
        score     = NA)
  } else {
    liv_status = liv_status %>%
      filter(year >= max(year, na.rm=T) - 4) %>% # reference point is 5 years ago
      arrange(rgn_id, year, sector) %>%
      # summarize across sectors
      group_by(rgn_id, year) %>%
      summarize(
        # across sectors, jobs are summed
        jobs_sum  = sum(jobs_adj, na.rm=T),
        # across sectors, wages are averaged
        wages_avg = mean(wage_usd, na.rm=T)) %>%
      group_by(rgn_id) %>%
      arrange(rgn_id, year) %>%
      mutate(
        # reference for jobs [j]: value in the current year (or most recent year) [c], relative to the value in a recent moving reference period [r] defined as 5 years prior to [c]
        jobs_sum_first  = first(jobs_sum),                     # note:  `first(jobs_sum, order_by=year)` caused segfault crash on Linux with dplyr 0.3.0.2, so using arrange above instead
        # original reference for wages [w]: target value for average annual wages is the highest value observed across all reporting units
        # new reference for wages [w]: value in the current year (or most recent year) [c], relative to the value in a recent moving reference period [r] defined as 5 years prior to [c]
        wages_avg_first = first(wages_avg)) %>% # note:  `first(jobs_sum, order_by=year)` caused segfault crash on Linux with dplyr 0.3.0.2, so using arrange above instead
      # calculate final scores
      ungroup() %>%
      mutate(
        x_jobs  = pmax(-1, pmin(1,  jobs_sum / jobs_sum_first)),
        x_wages = pmax(-1, pmin(1, wages_avg / wages_avg_first)),
        score   = mean(c(x_jobs, x_wages), na.rm=T) * 100) %>%
      # filter for most recent year
      filter(year == max(year, na.rm=T)) %>%
      # format
      select(
        region_id = rgn_id,
        score) %>%
      mutate(
        goal      = 'LIV',
        dimension = 'status')

    # LIV trend
    # From SOM p. 29: trend was calculated as the slope in the individual sector values (not summed sectors)
    # over the most recent five years...
    # with the average weighted by the number of jobs in each sector
    # ... averaging slopes across sectors weighted by the revenue in each sector

    # get trend across years as slope of individual sectors for jobs and wages
    liv_trend = liv %>%
      filter(!is.na(jobs_adj) & !is.na(wage_usd)) %>%
      # TODO: consider "5 year time spans" as having 5 [(max(year)-4):max(year)] or 6 [(max(year)-5):max(year)] member years
      filter(year >= max(year, na.rm=T) - 4) %>% # reference point is 5 years ago
      # get sector weight as total jobs across years for given region
      arrange(rgn_id, year, sector) %>%
      group_by(rgn_id, sector) %>%
      mutate(
        weight = sum(jobs_adj, na.rm=T)) %>%
      # reshape into jobs and wages columns into single metric to get slope of both with one do() call
      reshape2::melt(id=c('rgn_id','year','sector','weight'), variable='metric', value.name='value') %>%
      mutate(
        sector = as.character(sector),
        metric = as.character(metric)) %>%
      # get linear model coefficient per metric
      group_by(metric, rgn_id, sector, weight) %>%
      do(mdl = lm(value ~ year, data=.)) %>%
      summarize(
        metric = metric,
        weight = weight,
        rgn_id = rgn_id,
        sector = sector,
        # TODO: consider how the units affect trend; should these be normalized? cap per sector or later?
        sector_trend = pmax(-1, pmin(1, coef(mdl)[['year']] * 5))) %>%
      arrange(rgn_id, metric, sector) %>%
      # get weighted mean across sectors per region-metric
      group_by(metric, rgn_id) %>%
      summarize(
        metric_trend = weighted.mean(sector_trend, weight, na.rm=T)) %>%
      # get mean trend across metrics (jobs, wages) per region
      group_by(rgn_id) %>%
      summarize(
        score = mean(metric_trend, na.rm=T)) %>%
      # format
      mutate(
        goal      = 'LIV',
        dimension = 'trend') %>%
      select(
        goal, dimension,
        region_id = rgn_id,
        score)
  }


  # ECO calculations ----
  eco = le_gdp %>%
    mutate(
      rev_adj = gdp_usd,
      sector = 'gdp') %>%
    # adjust rev with national GDP rates if available. Example: (rev_adj = gdp_usd / ntl_gdp)
    select(rgn_id, year, sector, rev_adj)

  # ECO status
  eco_status = eco %>%
    filter(!is.na(rev_adj)) %>%
    filter(year >= max(year, na.rm=T) - 4) %>% # reference point is 5 years ago
    # across sectors, revenue is summed
    group_by(rgn_id, year) %>%
    summarize(
      rev_sum  = sum(rev_adj, na.rm=T)) %>%
    # reference for revenue [e]: value in the current year (or most recent year) [c], relative to the value in a recent moving reference period [r] defined as 5 years prior to [c]
    arrange(rgn_id, year) %>%
    group_by(rgn_id) %>%
    mutate(
      rev_sum_first  = first(rev_sum)) %>%
    # calculate final scores
    ungroup() %>%
    mutate(
      score  = pmin(rev_sum / rev_sum_first, 1) * 100) %>%
    # get most recent year
    filter(year == max(year, na.rm=T)) %>%
    # format
    mutate(
      goal      = 'ECO',
      dimension = 'status') %>%
    select(
      goal, dimension,
      region_id = rgn_id,
      score)

  # ECO trend
  eco_trend = eco %>%
    filter(!is.na(rev_adj)) %>%
    filter(year >= max(year, na.rm=T) - 4 ) %>% # 5 year trend
    # get sector weight as total revenue across years for given region
    arrange(rgn_id, year, sector) %>%
    group_by(rgn_id, sector) %>%
    mutate(
      weight = sum(rev_adj, na.rm=T)) %>%
    # get linear model coefficient per region-sector
    group_by(rgn_id, sector, weight) %>%
    do(mdl = lm(rev_adj ~ year, data=.)) %>%
    summarize(
      weight = weight,
      rgn_id = rgn_id,
      sector = sector,
      # TODO: consider how the units affect trend; should these be normalized? cap per sector or later?
      sector_trend = pmax(-1, pmin(1, coef(mdl)[['year']] * 5))) %>%
    # get weighted mean across sectors per region
    group_by(rgn_id) %>%
    summarize(
      score = weighted.mean(sector_trend, weight, na.rm=T)) %>%
    # format
    mutate(
      goal      = 'ECO',
      dimension = 'trend') %>%
    select(
      goal, dimension,
      region_id = rgn_id,
      score)

  # report LIV and ECO scores separately
  if (subgoal=='LIV'){
    d = rbind(liv_status, liv_trend)
  } else if (subgoal=='ECO'){
    d = rbind(eco_status, eco_trend)
  } else {
    stop('LIV_ECO function only handles subgoal of "LIV" or "ECO"')
  }
  return(d)

}


LE = function(scores, layers){

  # calculate LE scores
  scores.LE = scores %.%
    filter(goal %in% c('LIV','ECO') & dimension %in% c('status','trend','score','future')) %.%
    dcast(region_id + dimension ~ goal, value.var='score') %.%
    mutate(score = rowMeans(cbind(ECO, LIV), na.rm=T)) %.%
    select(region_id, dimension, score) %.%
    mutate(goal  = 'LE')

  # rbind to all scores
  scores = scores %.%
    rbind(scores.LE)

  # return scores
  return(scores)
}


ICO = function(layers){

  layers_data = SelectLayersData(layers, layers=c('ico_spp_extinction_status', 'ico_spp_popn_trend'))

   rk <- layers_data %>%
    select(region_id = id_num, sciname = category, iucn_cat=val_chr, layer)

  # lookup for weights status
  w.risk_category = data.frame(iucn_cat = c('LC', 'NT', 'VU', 'EN', 'CR', 'EX'),
                               risk_score = c(1,  0.8,   0.6,  0.4,  0.2,  0))

  # lookup for population trend
  w.popn_trend = data.frame(iucn_cat = c('decreasing', 'stable', 'increasing'),
                            trend_score = c(-0.5, 0, 0.5))

  ####### status
  # STEP 1: take mean of subpopulation scores
  r.status_spp <- rk %>%
    filter(layer == 'ico_spp_extinction_status') %>%
    left_join(w.risk_category) %>%
    group_by(region_id, sciname) %>%
    summarize(spp_mean = mean(risk_score, na.rm=TRUE) * 100) %>%
    ungroup()
  # STEP 2: take mean of populations within regions
  r.status <- r.status_spp %>%
    group_by(region_id) %>%
    summarize(score = mean(spp_mean, na.rm=TRUE))

  ####### trend
  # STEP 1: take mean of subpopulation scores
  r.trend_spp <- rk %>%
    filter(layer == 'ico_spp_popn_trend') %>%
    left_join(w.popn_trend) %>%
    group_by(region_id, sciname) %>%
    summarize(spp_mean = mean(trend_score, na.rm=TRUE)) %>%
    ungroup()
  # STEP 2: take mean of populations within regions
  r.trend <- r.trend_spp %>%
    group_by(region_id) %>%
    summarize(score = mean(spp_mean, na.rm=TRUE))

  # return scores
  s.status = cbind(r.status, data.frame('dimension'='status'))
  s.trend  = cbind(r.trend , data.frame('dimension'='trend' ))
  scores = cbind(rbind(s.status, s.trend), data.frame('goal'='ICO'))
  return(scores)

}

LSP = function(layers, ref_pct_cmpa=30, ref_pct_cp=30, status_year){
   trend_years = (status_year-4):status_year

  # select data ----
  r = SelectLayersData(layers, layers=c('rgn_area_inland1km', 'rgn_area_offshore3nm'))  #total offshore/inland areas
  ry = SelectLayersData(layers, layers=c('lsp_prot_area_offshore3nm', 'lsp_prot_area_inland1km')) #total protected areas

r <- r %>%
  select(region_id = id_num, val_num, layer) %>%
  spread(layer, val_num) %>%
  dplyr::rename(area_inland1km = rgn_area_inland1km,
                area_offshore3nm = rgn_area_offshore3nm)

ry <- ry %>%
  select(region_id = id_num, year, val_num, layer) %>%
  spread(layer, val_num) %>%
  dplyr::rename(cmpa = lsp_prot_area_offshore3nm,
                cp = lsp_prot_area_inland1km)

  # fill in time series for all regions and generate cumulative sum
r.yrs <- expand.grid(region_id = unique(ry$region_id),
                         year = unique(ry$year)) %>%
  left_join(ry, by=c('region_id', 'year')) %>%
  arrange(region_id, year) %>%
  mutate(cp= ifelse(is.na(cp), 0, cp),
         cmpa = ifelse(is.na(cmpa), 0, cmpa)) %>%
  group_by(region_id) %>%
  mutate(cp_cumsum    = cumsum(cp),
         cmpa_cumsum  = cumsum(cmpa)) %>%
  ungroup() %>%
 mutate(pa_cumsum     = cp_cumsum + cmpa_cumsum)

  # get percent of total area that is protected for inland1km (cp) and offshore3nm (cmpa) per year
  # and calculate status score
r.yrs = r.yrs %>%
  full_join(r) %>%
  mutate(pct_cp    = pmin(cp_cumsum   / area_inland1km   * 100, 100),
         pct_cmpa  = pmin(cmpa_cumsum / area_offshore3nm * 100, 100),
         prop_protected    = ( pmin(pct_cp / ref_pct_cp, 1) + pmin(pct_cmpa / ref_pct_cmpa, 1) ) / 2) %>%
  filter(!is.na(prop_protected))

# extract status based on specified year

  r.status = r.yrs %>%
    filter(year==status_year) %>%
    select(region_id, status=prop_protected) %>%
    mutate(status=status*100)
head(r.status)

  # calculate trend
  r.trend =   r.yrs %>%
  filter(year %in% trend_years) %>%
  group_by(region_id) %>%
  do(mdl = lm(prop_protected ~ year, data=.)) %>%
  summarize(
    region_id = region_id,
    trend = min(1, max(0, 5*coef(mdl)['year']))) %>% # set boundaries so trend does not go below 0 or above 1
   ungroup()

  # return scores
  scores = rbind.fill(
    within(r.status, {
      goal      = 'LSP'
      dimension = 'status'
      score     = status}),
    within(r.trend, {
      goal      = 'LSP'
      dimension = 'trend'
      score     = trend}))
  return(scores[,c('region_id','goal','dimension','score')])
}

SP = function(scores){

  d = within(
    dcast(
      scores,
      region_id + dimension ~ goal, value.var='score',
      subset=.(goal %in% c('ICO','LSP') & !dimension %in% c('pressures','resilience')))
    , {
      goal = 'SP'
      score = rowMeans(cbind(ICO, LSP), na.rm = TRUE)})


  # return all scores
  return(rbind(scores, d[,c('region_id','goal','dimension','score')]))
}


CW = function(layers){

  # layers
  lyrs = c('po_pathogens' = 'a',
           'po_nutrients_3nm' = 'u',
           'po_chemicals_3nm' = 'l',
           'po_trash'     = 'd',
           'cw_pesticide_trend'   = 'pest_trend',
           'cw_fertilizer_trend'  = 'fert_trend',
           'cw_coastalpopn_trend' = 'popn_trend',
           'cw_pathogen_trend'    = 'path_trend')

  # cast data
  d = SelectLayersData(layers, layers=names(lyrs))
  r = rename(dcast(d, id_num ~ layer, value.var='val_num', subset = .(layer %in% names(lyrs))),
              c('id_num'='region_id', lyrs)); head(r); summary(r)

  # invert pressures
  r$a = 1 - r$a
  r$u = 1 - r$u
  r$l = 1 - r$l
  r$d = 1 - r$d

  # invert trends for CW
  r$popn_trend = -1 * r$popn_trend
  r$path_trend = -1 * r$path_trend
  r$pest_trend = -1 * r$pest_trend
  r$fert_trend = -1 * r$fert_trend

geometric.mean2 <- function (x, na.rm = TRUE) {
    if (is.null(nrow(x))) {
      exp(mean(log(x), na.rm = TRUE))
    }
    else {
      exp(apply(log(x), 2, mean, na.rm = na.rm))
    }
  }

  # status
  r$status = geometric.mean2(t(r[,c('a','u','l','d')]), na.rm = TRUE) * 100

  # trend
  r$trend = rowMeans(r[,c('pest_trend','fert_trend','popn_trend','path_trend')], na.rm = TRUE)

  # return scores
  scores = rbind(
    within(r, {
      goal      = 'CW'
      dimension = 'status'
      score     = status}),
    within(r, {
      goal      = 'CW'
      dimension = 'trend'
      score     = trend}))[,c('region_id','goal','dimension','score')]
  return(scores)
}


HAB = function(layers){

  # get layer data
  d =
    join_all(
      list(

        layers$data[['hab_health']] %>%
          select(rgn_id, habitat, health),

        layers$data[['hab_trend']] %>%
          select(rgn_id, habitat, trend),

        layers$data[['hab_extent']] %>%
          select(rgn_id, habitat, extent=km2)),

      by = c('rgn_id','habitat'), type='full') %>%
    select(rgn_id, habitat, extent, health, trend)

  # limit to habitats used for HAB, create extent presence as weight
  d = d %>%
    filter(habitat %in% c('coral','mangrove','saltmarsh','seaice_edge','seagrass','soft_bottom')) %>%
    mutate(
      w  = ifelse(!is.na(extent) & extent > 0, 1, NA)) %>%
    filter(!is.na(w)) %>%
    group_by(rgn_id)

  # calculate scores
  scores_HAB = rbind_list(
    # status
    d %>%
      filter(!is.na(health)) %>%
      summarize(
        score = pmin(1, sum(w * health) / sum(w)) * 100,
        dimension = 'status'),
    # trend
    d %>%
      filter(!is.na(trend)) %>%
      summarize(
        score =  sum(w * trend) / sum(w),
        dimension = 'trend')) %>%
    mutate(
      goal = 'HAB') %>%
    select(region_id=rgn_id, goal, dimension, score)

  # return scores
  return(scores_HAB)
}


SPP = function(layers){

  # scores
  scores = cbind(rename(SelectLayersData(layers, layers=c('spp_status'='status','spp_trend'='trend'), narrow = TRUE),
                      c(id_num='region_id', layer='dimension', val_num='score')),
               data.frame('goal'='SPP'))
  scores = mutate(scores, score=ifelse(dimension=='status', score*100, score))
  return(scores)
}

BD = function(scores){

  d = within(
    dcast(
      scores,
      region_id + dimension ~ goal, value.var='score',
      subset=.(goal %in% c('HAB','SPP') & !dimension %in% c('pressures','resilience'))),
    {
      goal = 'BD'
      score = rowMeans(cbind(HAB, SPP), na.rm = TRUE)})

  # return all scores
  return(rbind(scores, d[,c('region_id','goal','dimension','score')]))
}

PreGlobalScores = function(layers, conf, scores){

  # get regions
  rgns = SelectLayersData(layers, layers=conf$config$layer_region_labels, narrow = TRUE)

  # limit to just desired regions and global (region_id==0)
  scores = subset(scores, region_id %in% c(rgns[,'id_num'], 0))

  # apply NA to Antarctica
  id_ant = subset(rgns, val_chr=='Antarctica', id_num, drop = TRUE)
  scores[scores$region_id==id_ant, 'score'] = NA

  return(scores)
}

FinalizeScores = function(layers, conf, scores){

  # get regions
  rgns = SelectLayersData(layers, layers=conf$config$layer_region_labels, narrow = TRUE)

  # add NAs to missing combos (region_id, goal, dimension)
  d = expand.grid(list(score_NA  = NA,
                       region_id = c(rgns[,'id_num'], 0),
                       dimension = c('pressures','resilience','status','trend','future','score'),
                       goal      = c(conf$goals$goal, 'Index')), stringsAsFactors = FALSE); head(d)
  d = subset(d,
             !(dimension %in% c('pressures','resilience','trend') & region_id==0) &
             !(dimension %in% c('pressures','resilience','status','trend') & goal=='Index'))
  scores = merge(scores, d, all = TRUE)[,c('goal','dimension','region_id','score')]

  # order
  scores = arrange(scores, goal, dimension, region_id)

  # round scores
  scores$score = round(scores$score, 2)

  return(scores)
}
